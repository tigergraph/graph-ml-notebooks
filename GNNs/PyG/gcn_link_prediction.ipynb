{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3482340-811d-429a-ba1f-80baca631c7e",
   "metadata": {},
   "source": [
    "# Graph Convolutional Network for Link Prediction\n",
    "This notebook demonstrates the training of [Graph Convolutional Networks (GCN)](https://arxiv.org/pdf/1609.02907.pdf) for Link Prediction with TigerGraph. Pytorch Geometric's implementation of GCN is used here. We train the model on the Cora dataset from [PyG datasets](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.Planetoid) with TigerGraph as the data store. The dataset contains 2708 machine learning papers and 10556 citation links between the papers. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from a dictionary. The dictionary consists of 1433 unique words. Each paper is classified into one of seven classes based on the topic. The goal is to predict whether two papers are linked or not.\n",
    "\n",
    "The following libraries are required to run this notebook. Uncomment to install them if necessary. You might need to restart the kernel after installing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch==1.12.0 --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "#!pip install torch-scatter==2.0.9 torch-sparse==0.6.14 torch-cluster==1.6.0 torch-spline-conv==1.2.1 torch-geometric==2.0.4 -f https://data.pyg.org/whl/torch-1.12.0+cpu.html\n",
    "#!pip install pyTigerGraph[gds]\n",
    "#!pip install tensorboard # If you use tensorboard for visualization later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5da30d",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Data Processing](#data_processing)  \n",
    "* [Whole Graph Training](#train_whole)  \n",
    "* [Stochastic Batch Training](#train_subgraph) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786d1fe-3758-4810-8c34-e66e59687a58",
   "metadata": {},
   "source": [
    "## Data Processing <a name=\"data_processing\"></a>\n",
    "\n",
    "For each edge, the original dataset include `is_train` and `is_val` attributes. You may add `is_test` if you want the train/validation/test splits. Otherwise, you can just use the edgeSplitter to get train/validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81383884-2fb9-46f6-9ce6-ad227abf4e52",
   "metadata": {},
   "source": [
    "### Connect to TigerGraph\n",
    "\n",
    "The `TigerGraphConnection` class represents a connection to the TigerGraph database. Under the hood, it stores the necessary information to communicate with the database. It is able to perform quite a few database tasks. Please see its [documentation](https://docs.tigergraph.com/pytigergraph/current/intro/) for details.\n",
    "\n",
    "To connect your database, modify the `config.json` file accompanying this notebook. Set the value of `getToken` based on whether token auth is enabled for your database. Token auth is always enabled for tgcloud databases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea45afd1-4fc3-4bc6-b739-2e89450df296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection\n",
    "import json\n",
    "\n",
    "# Read in DB configs\n",
    "with open('../../config.json', \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    \n",
    "conn = TigerGraphConnection(\n",
    "    host=config[\"host\"],\n",
    "    username=config[\"username\"],\n",
    "    password=config[\"password\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f59a78-4ea1-484d-98d3-caf908341395",
   "metadata": {},
   "source": [
    "### Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d25f25-0c8a-47ad-a9bb-efaf82699ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d7f736003a49f0937019846f40d70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/166537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyTigerGraph.datasets import Datasets\n",
    "\n",
    "dataset = Datasets(\"Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35ade5a-5bf2-4dac-9423-16a8dbf9bc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Checking database ----\n",
      "A graph with name Cora already exists in the database. Please drop it first before ingesting.\n"
     ]
    }
   ],
   "source": [
    "conn.ingestDataset(dataset, getToken=config[\"getToken\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140e9c7-b88d-4b69-9fe8-78143946ab8c",
   "metadata": {},
   "source": [
    "### Visualize Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b80ef0-d17d-4aca-9904-2a6c0f329536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435ed7fb03ab476bb238191bffe9101f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'circle', 'animate': True, 'padding': 1}, cytoscape_style=[{'selecto…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyTigerGraph.visualization import drawSchema\n",
    "\n",
    "drawSchema(conn.getSchema(force=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9ee2d-e355-4cfe-a620-3de819e58309",
   "metadata": {},
   "source": [
    "### Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c94459-35aa-4e5b-a23a-cfc57b4ecac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Paper': 2708}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.getVertexCount('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196ba830-ed69-4b1a-b77d-9aaff54e6d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cite': 10556}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.getEdgeCount('*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a23f94b-12e9-43c0-8d9c-20046bf59e13",
   "metadata": {},
   "source": [
    "### Train/validation split\n",
    "\n",
    "Split the edges into 80% train and 20% validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93935b53-cbe4-4838-a570-55b750b1fff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n",
      "CPU times: user 228 ms, sys: 39.5 ms, total: 268 ms\n",
      "Wall time: 49.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splitter = conn.gds.edgeSplitter(is_train=0.8, is_val=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54abea3e-9f99-4d7a-be06-6aa6630552de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting edges...\n",
      "Edge split finished successfully.\n",
      "CPU times: user 4.73 ms, sys: 945 µs, total: 5.68 ms\n",
      "Wall time: 72.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splitter.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63bc960-ec54-4755-b372-f40b367abce1",
   "metadata": {},
   "source": [
    "## Train on whole graph <a name=\"train_whole\"></a>\n",
    "\n",
    "Here, we use the full graph for link prediction. This will **NOT** work when the graph is very large. See the section of Stochastic Mini-Batch Training for real use. However, we still include this example for illustration purposes.\n",
    "\n",
    "We load the whole graph from TigerGraph which includes the feature and split results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182afd6a-a68d-4b28-8ac6-86e6a6b51e8f",
   "metadata": {},
   "source": [
    "### Construct graph loader and negative edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2544116b-4169-48ac-bd0f-049dfbcfc00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n"
     ]
    }
   ],
   "source": [
    "graph_loader = conn.gds.graphLoader(\n",
    "    num_batches=1,\n",
    "    v_in_feats = [\"x\"],\n",
    "    e_extra_feats=[\"is_train\",\"is_val\"],\n",
    "    output_format = \"PyG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "874be99d-9c9b-485c-ad75-7581132780a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a1443b-e53d-4c0d-994d-b3e2a50e8a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10556], is_train=[10556], is_val=[10556], x=[2708, 1433])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca4fdb7-94d1-4d46-a041-ad280efeb6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_index = data.edge_index[:, data.is_train]\n",
    "val_edge_index = data.edge_index[:, data.is_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10410e24-e984-4c4d-9b54-61f66078f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "neg_val_edge = torch.randint(0, data.x.shape[0], val_edge_index.size(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abdd6e53-13e0-4299-8fee-b5ee9a90b2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8454]), torch.Size([2, 2102]), torch.Size([2, 2102]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edge_index.shape, val_edge_index.shape, neg_val_edge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef04bf96-ffc1-45ad-91f8-b490258668a3",
   "metadata": {},
   "source": [
    "### Construct GCN Model\n",
    "\n",
    "We use dot product to measure the similarity of two nodes in a decode function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4bc349b-4830-4459-bf95-206cbe89d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, **kwargs):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index):\n",
    "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1) # concatenate pos and neg edges\n",
    "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)  # dot product \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a6bfba-3157-4330-ae6c-49e25a18491e",
   "metadata": {},
   "source": [
    "### Get binary labels for positive and negative edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d5123bd-2ebc-43a6-a9b3-ac0d503c0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(E, dtype=torch.float)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939e07f7-e6ae-4bea-ad82-3f549ddeba42",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a631ec03-1a9a-41a0-9734-ab7ff3dea269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = {\"hidden_dim\": 128, \"out_dim\": 64, \"num_layers\": 2,\n",
    "      \"dropout\": 0.6, \"lr\": 0.01, \"l2_penalty\": 5e-4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db9abec-dc1c-401c-a3f0-7693c768ae3f",
   "metadata": {},
   "source": [
    "### Instantiate Model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcbc8fca-6eff-4238-928f-f51eb936496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(1433, hp[\"hidden_dim\"], hp[\"out_dim\"], hp[\"num_layers\"], hp[\"dropout\"])\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=hp[\"lr\"], weight_decay=hp[\"l2_penalty\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0e9a355-e46b-4626-8a35-c5360dec07bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels = get_link_labels(val_edge_index, neg_val_edge)\n",
    "val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a700bfa-253a-4868-877b-194598b30c07",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cde228b-fd55-4116-88ad-dbcb787be5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a894353-20f1-42d0-9d7e-6297a3cb4e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training loss: 0.6500421166419983, valid roc_auc_score: 0.8383314427562532\n",
      "Epoch: 1, training loss: 1.081446886062622, valid roc_auc_score: 0.812061323500522\n",
      "Epoch: 2, training loss: 1.1687164306640625, valid roc_auc_score: 0.7562404886470317\n",
      "Epoch: 3, training loss: 0.6771160364151001, valid roc_auc_score: 0.8145703742799436\n",
      "Epoch: 4, training loss: 0.6512936949729919, valid roc_auc_score: 0.8144599271592186\n",
      "Epoch: 5, training loss: 0.6514720320701599, valid roc_auc_score: 0.8029452490084655\n",
      "Epoch: 6, training loss: 0.6470925211906433, valid roc_auc_score: 0.7915663664979481\n",
      "Epoch: 7, training loss: 0.6444706916809082, valid roc_auc_score: 0.7924901163406516\n",
      "Epoch: 8, training loss: 0.6450539827346802, valid roc_auc_score: 0.8071957657108768\n",
      "Epoch: 9, training loss: 0.6447546482086182, valid roc_auc_score: 0.7999462022938599\n",
      "Epoch: 10, training loss: 0.6415925025939941, valid roc_auc_score: 0.7999011634065152\n",
      "Epoch: 11, training loss: 0.6420110464096069, valid roc_auc_score: 0.7940671563759222\n",
      "Epoch: 12, training loss: 0.6354835033416748, valid roc_auc_score: 0.8104411683494763\n",
      "Epoch: 13, training loss: 0.6298680305480957, valid roc_auc_score: 0.8130789986610549\n",
      "Epoch: 14, training loss: 0.617591917514801, valid roc_auc_score: 0.8237532149617826\n",
      "Epoch: 15, training loss: 0.6072716116905212, valid roc_auc_score: 0.845905105101299\n",
      "Epoch: 16, training loss: 0.5972340703010559, valid roc_auc_score: 0.8635679308637236\n",
      "Epoch: 17, training loss: 0.5859787464141846, valid roc_auc_score: 0.8642446458042314\n",
      "Epoch: 18, training loss: 0.569355845451355, valid roc_auc_score: 0.8725765004739267\n",
      "Epoch: 19, training loss: 0.559634268283844, valid roc_auc_score: 0.880606549333198\n",
      "Epoch: 20, training loss: 0.5440987348556519, valid roc_auc_score: 0.8762095996653996\n",
      "Epoch: 21, training loss: 0.5339546799659729, valid roc_auc_score: 0.884704295940344\n",
      "Epoch: 22, training loss: 0.5243106484413147, valid roc_auc_score: 0.883151133305148\n",
      "Epoch: 23, training loss: 0.513563871383667, valid roc_auc_score: 0.890787374807736\n",
      "Epoch: 24, training loss: 0.5073722004890442, valid roc_auc_score: 0.8890371953311649\n",
      "Epoch: 25, training loss: 0.5005218982696533, valid roc_auc_score: 0.895701366375732\n",
      "Epoch: 26, training loss: 0.4956182837486267, valid roc_auc_score: 0.9078041528117392\n",
      "Epoch: 27, training loss: 0.4941596984863281, valid roc_auc_score: 0.9012601609087806\n",
      "Epoch: 28, training loss: 0.4928068220615387, valid roc_auc_score: 0.8992277528265863\n",
      "Epoch: 29, training loss: 0.48640885949134827, valid roc_auc_score: 0.9051891814329338\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    neg_train_edge = torch.randint(0, data.x.shape[0], train_edge_index.size(), dtype=torch.long)\n",
    "    h = model(data.x.float(), train_edge_index)\n",
    "    logits = model.decode(h, train_edge_index, neg_train_edge)\n",
    "    labels = get_link_labels(train_edge_index, neg_train_edge)\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_logits = model.decode(h, val_edge_index, neg_val_edge)\n",
    "        val_logits = val_logits.sigmoid()\n",
    "        print('Epoch: {}, training loss: {}, valid roc_auc_score: {}'.format(epoch, loss.item(), roc_auc_score(val_labels, val_logits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad2acb3-f850-42aa-8333-ab82733d72bb",
   "metadata": {},
   "source": [
    "## Stochastic Batch Training <a name=\"train_subgraph\"></a>\n",
    "\n",
    "For stochastic batch training, we split the training edges into batches. At each specific batch, to do the link prediction, we need to know the neighbor graphs for each pair of nodes that has an edge.\n",
    "\n",
    "We use the edgeNeighborLoader, which can load the neighbors of the pair nodes of an edge and has the same parameters as neighborLoader(). The result of a batch is, for example,\n",
    "\n",
    "`Data(edge_index=[2, 6917], is_train=[6917], is_val=[6917], is_test=[6917], is_seed=[6917], x=[2188, 1433], y=[2188])`\n",
    "\n",
    "where `is_seed` indicates whether each edge is a seed edge or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a41d8aa-55f7-4e31-a2b0-3edcfc1cd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = {\"hidden_dim\": 128, \"out_dim\": 64, \"num_layers\": 2,\n",
    "      \"dropout\": 0.6, \"lr\": 0.01, \"l2_penalty\": 5e-4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f89253-93ca-479b-8d1c-5a06bef9aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(1433, hp[\"hidden_dim\"], hp[\"out_dim\"], hp[\"num_layers\"], hp[\"dropout\"])\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=hp[\"lr\"], weight_decay=hp[\"l2_penalty\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb697c-7355-46e0-b6ab-f54750eedb85",
   "metadata": {},
   "source": [
    "### Construct the edge_neighbor_loader for train/val edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2711014-81ce-4ff4-8959-3e251b7bf394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n"
     ]
    }
   ],
   "source": [
    "train_edge_neighbor_loader = conn.gds.edgeNeighborLoader(\n",
    "    v_in_feats=[\"x\"],\n",
    "    v_out_labels=[\"y\"],\n",
    "    batch_size=1000,\n",
    "    e_extra_feats=[\"is_train\",\"is_val\"],\n",
    "    output_format=\"PyG\",\n",
    "    num_neighbors=10,\n",
    "    num_hops=2,\n",
    "    filter_by=\"is_train\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e02ab37-dcf2-4681-971d-04a2ae8ed0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_edge_neighbor_loader = conn.gds.edgeNeighborLoader(\n",
    "    v_in_feats=[\"x\"],\n",
    "    v_out_labels=[\"y\"],\n",
    "    batch_size=500,\n",
    "    e_extra_feats=[\"is_train\",\"is_val\"],\n",
    "    output_format=\"PyG\",\n",
    "    num_neighbors=10,\n",
    "    num_hops=2,\n",
    "    filter_by=\"is_val\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6ab8a-a266-48f5-97ae-38aab5a2bab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training loss: 3.904411494731903, valid roc_auc_score: 0.8237392959086584\n",
      "Epoch: 1, training loss: 3.1914963126182556, valid roc_auc_score: 0.8996884395360859\n",
      "Epoch: 2, training loss: 2.9413991570472717, valid roc_auc_score: 0.9132218330419763\n",
      "Epoch: 3, training loss: 2.5968366861343384, valid roc_auc_score: 0.9252033087060395\n",
      "Epoch: 4, training loss: 2.427817314863205, valid roc_auc_score: 0.9299228861824314\n",
      "Epoch: 5, training loss: 2.3323494493961334, valid roc_auc_score: 0.9444609410999989\n",
      "Epoch: 6, training loss: 2.3284645080566406, valid roc_auc_score: 0.9524406324093495\n",
      "Epoch: 7, training loss: 2.2777881622314453, valid roc_auc_score: 0.9523057420733823\n",
      "Epoch: 8, training loss: 2.2383748292922974, valid roc_auc_score: 0.9618454989629739\n",
      "Epoch: 9, training loss: 2.2285644710063934, valid roc_auc_score: 0.9601150098542369\n",
      "Epoch: 10, training loss: 2.2250851690769196, valid roc_auc_score: 0.9643573788182338\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for bid, batch in enumerate(train_edge_neighbor_loader):\n",
    "        # get the training edges and negative edges sampled in the same batch\n",
    "        train_edges = batch.edge_index[:, batch.is_seed]\n",
    "        neg_train_edges = torch.randint(0, batch.x.shape[0], train_edges.size(), dtype=torch.long)\n",
    "        # The graph only include the edges whose is_train is True\n",
    "        train_graph_edges = batch.edge_index[:, batch.is_train]\n",
    "        h = model(batch.x.float(), train_graph_edges)\n",
    "        logits = model.decode(h, train_edges, neg_train_edges)\n",
    "        labels = get_link_labels(train_edges, neg_train_edges)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_logits = []\n",
    "    for batch in val_edge_neighbor_loader:\n",
    "        val_edges = batch.edge_index[:, batch.is_seed]\n",
    "        neg_val_edges = torch.randint(0, batch.x.shape[0], val_edges.size(), dtype=torch.long)\n",
    "        # Need to use the train edge for GCN\n",
    "        val_graph_edges = batch.edge_index[:, batch.is_train]\n",
    "        with torch.no_grad():\n",
    "            h = model(batch.x.float(), val_graph_edges)\n",
    "            logits = model.decode(h, val_edges, neg_val_edges)\n",
    "            labels = get_link_labels(val_edges, neg_val_edges)\n",
    "            logits = logits.sigmoid()\n",
    "            all_labels.extend(labels)\n",
    "            all_logits.extend(logits)\n",
    "    print('Epoch: {}, training loss: {}, valid roc_auc_score: {}'.format(epoch, total_loss, roc_auc_score(all_labels, all_logits)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8f8df-e966-4c91-845e-03c2161ad8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc5eadac82f5951e7eb836bb06f3c9df8e6d1eda5537a95773af6c6ed24cb2d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
